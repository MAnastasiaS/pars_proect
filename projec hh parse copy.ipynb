{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests      # Для запросов по API\n",
    "import json          # Для обработки полученных результатов\n",
    "import time          # Для задержки между запросами\n",
    "import os            # Для работы с файлами\n",
    "import pandas as pd             # Для удобной загрузки данных в БД              # Для подключения к СУБД\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "def get_page(text, pg=0):\n",
    "    # Справочник параметров GET-запроса\n",
    "    params = {\n",
    "        'text': text,               # Текст поискового запроса\n",
    "        'area': 1,                  # Индекс города Москва\n",
    "        'page': pg,                 # Индекс страницы поиска на HH\n",
    "        'per_page': 100             # Кол-во вакансий на 1 странице\n",
    "    }\n",
    "    # Чтобы спарсить вакансии со страницы, нужно выполнить методом GET http-запрос,\n",
    "    # включая параметры фильтра поиска (ответ приходит в формате json):\n",
    "    url = 'https://api.hh.ru/vacancies'\n",
    "    \n",
    "    req = requests.get(url, params, timeout=20)  # Запрос к API\n",
    "    data = req.content.decode()                 # Декодирование ответа (для Кириллицы)\n",
    "    return data\n",
    "\n",
    "text_filter = '\"Data Engineer\" OR \"ML Engineer\" OR \"ETL Developer\"'\n",
    "\n",
    "page_result_list = []\n",
    "# Считывание 10000 вакансий (100 страниц по 100 вакансий)\n",
    "for page in range(0, 100):\n",
    "    print(page)\n",
    "    # Преобразование текстового ответа запроса в словарь\n",
    "    page_dict = json.loads(get_page(text_filter, page))\n",
    "\n",
    "    # Сохранение страниц в список\n",
    "    page_result_list+=page_dict['items']\n",
    "\n",
    "    # Условие выхода из цикла (если страниц окажется меньше 100)\n",
    "    if (page_dict['pages'] - page) <= 1:\n",
    "        break\n",
    "    # Задержка, чтобы не нагружать сервисы hh\n",
    "    time.sleep(0.25)\n",
    "print('Страницы поиска собраны')\n",
    "\n",
    "repr= []\n",
    "for i in page_result_list:\n",
    "    try:\n",
    "        d_mvf={'id':str(i['id']),\n",
    "        'name':i['name'],\n",
    "        'department':i['department'] if i['department']==None else i['department']['name'],\n",
    "        'response_letter_required':1 if i['response_letter_required'] else 0,\n",
    "        'type':i['type']['name'],\n",
    "        'lat':i['address']['lat'],\n",
    "        'lng':i['address']['lng'],\n",
    "        'created_at':i['created_at'][:-6],\n",
    "        'employer': i['employer']['name'],\n",
    "        'accredited_it_employer': 1 if 'accredited_it_employer' in i['employer'].keys() else 0,\n",
    "        'schedule':i['schedule']['name'],\n",
    "        'accept_temporary':1 if i['accept_temporary'] else 0,\n",
    "        'professional_roles':i['professional_roles'][0]['name'],\n",
    "        'experience':np.mean([int(i) for i in i['experience']['name'].split(' ') if i.isnumeric()]),\n",
    "        'employment':i['employment']['name']}\n",
    "        \n",
    "        if 'salary' in i.keys():\n",
    "            d_mvf['salary']=i['salary'] if i['salary']==None else i['salary']['from']\n",
    "        repr+=[d_mvf]\n",
    "    except:\n",
    "        pass\n",
    "repr = pd.DataFrame(repr)\n",
    "repr[['response_letter_required','accredited_it_employer','accept_temporary']]=repr[['response_letter_required','accredited_it_employer','accept_temporary']].fillna(0).astype(str)\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# Устанавливаем соединение с базой данных\n",
    "connection = sqlite3.connect('my_database.db')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "\n",
    "# Выбираем всех пользователей\n",
    "cursor.execute('SELECT id FROM resume_data ')\n",
    "users = cursor.fetchall()\n",
    "\n",
    "users = [i[0] for i in list(users)]\n",
    "print(list(users))\n",
    "\n",
    "repr= repr.loc[~repr.id.isin(list(users))]\n",
    "\n",
    "for i in range(len(repr)):\n",
    "    data= list(repr.iloc[i])\n",
    "    print(data)\n",
    "    cursor.execute('''INSERT INTO resume_data (\n",
    "    id,name,department,response_letter_required,type,lat,lng,created_at,employer,accredited_it_employer,schedule,accept_temporary,professional_roles,experience,employment,salary\n",
    "\n",
    "    ) VALUES (?, ?, ?, ?, ?,?, ?, ?, ?, ?,?, ?, ?, ?, ?, ?)''', data)\n",
    "    connection.commit()\n",
    "    \n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Устанавливаем соединение с базой данных\n",
    "connection = sqlite3.connect(r'C:\\Users\\nasty\\OneDrive\\Рабочий стол\\hh')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "\n",
    "# Выбираем всех пользователей\n",
    "cursor.execute('SELECT * FROM resume_data ')\n",
    "users = cursor.fetchall()\n",
    "df = pd.DataFrame(list(users),columns = ['id', 'name', 'department', 'response_letter_required', 'type', 'lat',\n",
    "    'lng', 'created_at', 'employer', 'accredited_it_employer', 'schedule',\n",
    "    'accept_temporary', 'professional_roles', 'experience', 'employment',\n",
    "    'salary'])\n",
    "\n",
    "df['date'] = pd.to_datetime(df['created_at'])\n",
    "df[['response_letter_required','accredited_it_employer','accept_temporary',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "# Устанавливаем соединение с базой данных\n",
    "\n",
    "dir_current = os.getcwd()\n",
    "# Устанавливаем соединение с базой данных\n",
    "connection = sqlite3.connect(dir_current+'/my_database.db')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "cursor.execute('''drop TABLE resume_data ''')\n",
    "# Создаем таблицу Users\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS resume_data (\n",
    "id                           text,\n",
    "name                         text,\n",
    "department                   text,\n",
    "response_letter_required       text,\n",
    "type                         text,\n",
    "lat                         float,\n",
    "lng                         float,\n",
    "created_at                   date,\n",
    "employer                     text,\n",
    "accredited_it_employer         text,\n",
    "schedule                     text,\n",
    "accept_temporary               text,\n",
    "professional_roles           text,\n",
    "experience                  float,\n",
    "employment                   text,\n",
    "salary                      float\n",
    "\n",
    ")''')\n",
    "\n",
    "# Сохраняем изменения и закрываем соединение\n",
    "connection.commit()\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
